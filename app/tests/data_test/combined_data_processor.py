import pandas as pd
import numpy as np
import re
import ast
import os
from sentence_transformers import SentenceTransformer
import pymongo

# File paths
VECTORS_CSV = "vectors.csv"
CLEAN_CSV = "vectors_clean.csv"
VECTORS_NPY = "vectors.npy"

def generate_vectors(output_csv_path, model_name='all-MiniLM-L6-v2'):
    # Connect to MongoDB
    connection_string = "mongodb+srv://trung7cyv:Pwrl2KClurSIANRy@cluster0.wwa6we5.mongodb.net/?retryWrites=true&w=majority"
    client = pymongo.MongoClient(connection_string)
    
    # Explicitly specify the database name
    db = client["news_scraper"]
    
    # Assuming the collection name is "articles" - adjust if needed
    collection = db["articles"]
    
    # Check if we already have processed documents
    existing_df = None
    existing_mongo_ids = set()
    max_existing_id = 0
    
    if os.path.exists(output_csv_path):
        print(f"üìÇ T√¨m th·∫•y file vectors hi·ªán c√≥: {output_csv_path}")
        existing_df = pd.read_csv(output_csv_path)
        
        if 'mongo_id' in existing_df.columns:
            # Extract existing MongoDB IDs to avoid reprocessing
            existing_mongo_ids = set(existing_df['mongo_id'].astype(str))
            print(f"‚úÖ ƒê√£ t√¨m th·∫•y {len(existing_mongo_ids)} documents ƒë√£ x·ª≠ l√Ω tr∆∞·ªõc ƒë√≥")
            
            # Find the maximum existing ID to continue sequential numbering
            if 'id' in existing_df.columns and not existing_df['id'].empty:
                max_existing_id = existing_df['id'].max()
                print(f"‚úÖ ID hi·ªán t·∫°i l·ªõn nh·∫•t: {max_existing_id}")
    
    # Retrieve all documents from MongoDB
    print("üìä ƒêang k·∫øt n·ªëi v√† l·∫•y d·ªØ li·ªáu t·ª´ MongoDB...")
    all_documents = list(collection.find({}))
    print(f"‚úÖ ƒê√£ l·∫•y {len(all_documents)} documents t·ª´ MongoDB")
    
    # Filter out documents that have already been processed
    new_documents = [doc for doc in all_documents if str(doc.get("_id", "")) not in existing_mongo_ids]
    print(f"üîç T√¨m th·∫•y {len(new_documents)} documents m·ªõi c·∫ßn x·ª≠ l√Ω")
    
    if not new_documents:
        print("‚úÖ Kh√¥ng c√≥ documents m·ªõi, gi·ªØ nguy√™n file hi·ªán t·∫°i")
        return existing_df
    
    # Create dataframe with required fields and assign sequential integer IDs
    data = []
    for i, doc in enumerate(new_documents, max_existing_id + 1):  # Continue numbering from max ID
        # Extract fields, use empty string if not present
        mongo_id = str(doc.get("_id", ""))
        title = doc.get("title", "")
        content = doc.get("content", "")
        
        data.append({
            "id": i,
            "mongo_id": mongo_id,
            "title": title, 
            "content": content
        })
    
    new_df = pd.DataFrame(data)
    
    # Load model
    print("üîÑ ƒêang t·∫£i m√¥ h√¨nh embedding...")
    model = SentenceTransformer(model_name)
    
    # Ensure title and content columns exist before combining
    if 'title' not in new_df.columns or 'content' not in new_df.columns:
        print("WARNING: Required columns not found in data")
        # Create missing columns with empty strings if they don't exist
        if 'title' not in new_df.columns:
            new_df['title'] = ''
        if 'content' not in new_df.columns:
            new_df['content'] = ''
    
    # Combine title and content
    new_df['text'] = new_df['title']
    
    # Generate embeddings
    print(f"üîÑ ƒêang t·∫°o embedding cho {len(new_df)} documents m·ªõi, vui l√≤ng ch·ªù...")
    embeddings = model.encode(new_df['text'].tolist(), show_progress_bar=True)
    
    # Create output dataframe with id and vector
    new_output_df = pd.DataFrame({
        'id': new_df['id'],
        'mongo_id': new_df['mongo_id'],  # Include MongoDB ID for reference
        'vector': [list(vec) for vec in embeddings]  # Convert numpy array to list
    })
    
    # Combine existing and new data if needed
    if existing_df is not None:
        combined_df = pd.concat([existing_df, new_output_df], ignore_index=False)
        print(f"‚úÖ ƒê√£ k·∫øt h·ª£p {len(existing_df)} documents c≈© v√† {len(new_output_df)} documents m·ªõi")
    else:
        combined_df = new_output_df
    
    # Save combined dataframe
    combined_df.to_csv(output_csv_path, index=False)
    print(f"‚úÖ ƒê√£ l∆∞u file vector t·∫°i: {output_csv_path}")
    
    return combined_df

def parse_np_float32_string(vec_str):
    # Tr√≠ch xu·∫•t t·∫•t c·∫£ s·ªë th·ª±c t·ª´ ƒë·ªãnh d·∫°ng np.float32(...)
    numbers = re.findall(r'np\.float32\(([-+]?\d*\.?\d+(?:[eE][-+]?\d+)?)\)', vec_str)
    return [float(num) for num in numbers]

def clean_vectors(input_csv, output_csv, output_npy):
    print("ƒêang ƒë·ªçc file g·ªëc...")
    df = pd.read_csv(input_csv)

    print("ƒêang √©p ki·ªÉu ID v·ªÅ s·ªë nguy√™n...")
    df = df.dropna(subset=['id'])  # B·ªè h√†ng thi·∫øu ID n·∫øu c√≥
    df['id'] = df['id'].astype(int)

    print("ƒêang x·ª≠ l√Ω vector...")
    # Check if the vector needs parsing (string with np.float32) or is already in list format
    first_vec = df["vector"].iloc[0] if not df.empty else ""
    
    if isinstance(first_vec, str) and "np.float32" in first_vec:
        print("Ph√°t hi·ªán ƒë·ªãnh d·∫°ng np.float32, ƒëang chuy·ªÉn ƒë·ªïi...")
        df["vector_clean"] = df["vector"].apply(parse_np_float32_string)
    else:
        print("Ph√°t hi·ªán ƒë·ªãnh d·∫°ng list, s·ª≠ d·ª•ng tr·ª±c ti·∫øp...")
        df["vector_clean"] = df["vector"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)

    print(f"L∆∞u file CSV s·∫°ch v√†o {output_csv}...")
    # Include mongo_id in the output if it exists
    if 'mongo_id' in df.columns:
        df_out = df[["id", "mongo_id", "vector_clean"]].rename(columns={"vector_clean": "vector"})
    else:
        df_out = df[["id", "vector_clean"]].rename(columns={"vector_clean": "vector"})
    
    df_out.to_csv(output_csv, index=False)

    print(f"L∆∞u file nh·ªã ph√¢n .npy v√†o {output_npy}...")
    np_vectors = np.array(df_out["vector"].apply(lambda x: np.array(x)).tolist(), dtype=np.float32)
    np.save(output_npy, np_vectors)

    print("‚úÖ Ho√†n t·∫•t qu√° tr√¨nh l√†m s·∫°ch vector!")

def main():
    print("üöÄ B·∫Øt ƒë·∫ßu quy tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu...")
    
    # Step 1: Generate vectors from MongoDB data (only for new documents)
    print("\n=== PHASE 1: GENERATING VECTORS FROM MONGODB (INCREMENTAL) ===")
    generate_vectors(VECTORS_CSV)
    
    # Step 2: Clean the vectors and save in the required formats
    print("\n=== PHASE 2: CLEANING AND PROCESSING VECTORS ===")
    clean_vectors(VECTORS_CSV, CLEAN_CSV, VECTORS_NPY)
    
    print("\n‚úÖ TO√ÄN B·ªò QUY TR√åNH ƒê√É HO√ÄN T·∫§T!")

if __name__ == "__main__":
    main()
